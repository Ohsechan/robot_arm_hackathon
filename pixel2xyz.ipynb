{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel Coordinates: (6, 45)\n",
      "Ground Coordinates: (197.19067875157805, -124.63002742074174, -23.12964228423216)\n"
     ]
    }
   ],
   "source": [
    "# 1~3층\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def return_models():\n",
    "    # Assuming you have a list of 60 pairs of known coordinates, where each pair is a tuple (pixel, ground)\n",
    "    known_coordinates = [\n",
    "        ((18, 57), (197.23245763, -129.12501306, -56.3813591)),\n",
    "        ((20, 148), (237.03232681, -129.8347899, -55.1228981)),\n",
    "        ((24, 244), (279.65948514, -129.61270702, -54.21435547)),\n",
    "        ((18, 341), (323.07916804, -131.03121387, -53.35089111)),\n",
    "        ((22, 434), (364.3658895,  -132.93345849,  -52.61401367)),\n",
    "\n",
    "        ((113, 440), (365.99875432, -93.13478301, -52.76441193)),\n",
    "        ((112, 346), (323.64471814, -92.12248261, -53.47555161)),\n",
    "        ((114, 252), (282.50840583, -89.40424259, -54.4005928)),\n",
    "        ((109, 158), (241.22091743, -90.91305604, -55.43299484)),\n",
    "        ((107, 59), (200.71304314, -90.02148843, -56.50268173)),\n",
    "\n",
    "        ((211, 59), (200.65669671, -45.2547401, -56.82236099)),\n",
    "        ((214, 150), (240.44854821, -43.781955, -55.68135071)),\n",
    "        ((216, 248), (282.88066543, -45.28531358, -54.45090866)),\n",
    "        ((216, 348), (327.21290222, -45.39544268, -53.78822327)),\n",
    "        ((214, 439), (365.46261504, -47.08075127, -52.94409943)),\n",
    "\n",
    "        ((316, 443), (368.10167265,  -5.44055345, -52.71708298)),\n",
    "        ((312, 340), (323.85736509,  -4.60735722, -53.7513504)),\n",
    "        ((312, 243), (283.08711969,  -4.61066233, -54.57106781)),\n",
    "        ((304, 149), (241.73684576,  -7.39499489, -55.70578766)),\n",
    "        ((297, 55), (241.7353931,   -7.39107994, -55.70512009)),\n",
    "\n",
    "        ((396, 54), (202.32955248,  33.11814487, -56.61216354)),\n",
    "        ((396, 151), (242.99959034,  32.33626195, -55.59835434)),\n",
    "        ((394, 250), (284.98097612,  31.97357895, -54.62459564)),\n",
    "        ((392, 345), (326.37177254,  28.20765976, -53.52246094)),\n",
    "        ((394, 442), (367.88949361,  29.06712429, -53.00455856)),\n",
    "\n",
    "        ((494, 438), (369.27175939,  75.52638341, -53.10138321)),\n",
    "        ((491, 347), (328.27403202,  72.76315009, -53.51223373)),\n",
    "        ((492, 250), (286.26486106,  73.65882619, -54.36959839)),\n",
    "        ((490, 150), (243.90656323,  73.57582243, -55.71626282)),\n",
    "        ((485, 57), (203.07752679,  73.43904425, -56.37465286)),\n",
    "\n",
    "        ((583, 62), (205.98353395, 115.3134969, -56.00774002)),\n",
    "        ((586, 168), (249.75791539, 115.10760312, -55.15762329)),\n",
    "        ((585, 258), (291.4853062,  113.80636915, -54.09247208)),\n",
    "        ((581, 351), (332.79315307, 111.89546848, -53.34688568)),\n",
    "        ((582, 447), (374.86175399, 112.87254096, -52.6618576))\n",
    "    ]\n",
    "\n",
    "    # Separate the known pixel coordinates (x, y) and ground coordinates (X, Y)\n",
    "    pixel_coords, ground_coords = zip(*known_coordinates)\n",
    "\n",
    "    # Fit a linear regression model\n",
    "    layer1_model = LinearRegression()\n",
    "    layer1_model.fit(pixel_coords, np.array(ground_coords))\n",
    "\n",
    "    # Assuming you have a list of 60 pairs of known coordinates, where each pair is a tuple (pixel, ground)\n",
    "    known_coordinates = [\n",
    "        ((10, 50), (196.60525204, -127.71492103,  -39.7327652)),\n",
    "        ((3, 147), (236.79669074, -130.42751964,  -38.91947937)),\n",
    "        ((7, 249), (279.93618316, -129.31368057,  -37.91059875)),\n",
    "        ((7, 343), (319.75019608, -131.76667078,  -36.93005371)),\n",
    "        ((13, 444), (362.48222568, -131.96776319,  -36.39452362)),\n",
    "\n",
    "        ((101, 436), (358.92113256, -91.26896158, -36.70382309)),\n",
    "        ((104, 340), (318.88001934, -90.09066663, -37.25808334)),\n",
    "        ((106, 242), (278.37647735, -87.99474394, -38.11831665)),\n",
    "        ((105, 144), (236.05101672, -87.13672135, -38.76483536)),\n",
    "        ((109, 43), (192.029174, -86.65258025, -40.19099808)),\n",
    "\n",
    "        ((202, 34), (202.87756465, -44.42757043, -40.02145386)),\n",
    "        ((206, 156), (243.89436713, -44.4400176,  -39.216362)),\n",
    "        ((208, 257), (285.40195948, -46.00454792, -38.2682457)),\n",
    "        ((210, 357), (326.64944832, -45.57396972, -37.26883698)),\n",
    "        ((212, 456), (369.00689464, -45.67850608, -36.33891678)),\n",
    "\n",
    "        ((320, 452), (367.64777163,  -1.06787572, -36.46825409)),\n",
    "        ((327, 343), (323.11824299,   2.62133152, -37.46490097)),\n",
    "        ((329, 245), (281.99978086,   4.46301795, -38.41419601)),\n",
    "        ((328, 143), (239.51033571,   5.59790164, -39.50374603)),\n",
    "        ((332, 45), (200.68459691,  6.71945741, -40.2234993)),\n",
    "\n",
    "        ((448, 40), (198.48583961,  55.58058365, -40.31784058)),\n",
    "        ((443, 14), (240.57749569,  51.2817749,  -39.27999115)),\n",
    "        ((439, 248), (282.12178493,  50.71386291, -38.52091217)),\n",
    "        ((436, 341), (322.45223208,  47.70041451, -37.48664856)),\n",
    "        ((445, 443), (366.31663137,  51.2958846,  -36.5300293)),\n",
    "\n",
    "        ((517, 442), (367.65763412,  81.31130988, -36.39893723)),\n",
    "        ((521, 341), (324.67086927,  84.7891222,  -37.23902512)),\n",
    "        ((524, 237), (281.45212731,  86.11030568, -38.08090973)),\n",
    "        ((520, 139), (240.98520327,  85.8553433,  -39.12801743)),\n",
    "        ((517, 45), (200.2511398,   85.284924,   -39.98502731)),\n",
    "\n",
    "        ((623, 45), (201.82164,    131.37262508, -39.6483078)),\n",
    "        ((626, 148), (243.4484499,  130.8261702,  -38.86640167)),\n",
    "        ((626, 246), (284.89912306, 129.34500424, -37.89682007)),\n",
    "        ((622, 343), (325.88543343, 127.25904337, -37.10594177)),\n",
    "        ((618, 444), (371.00444078, 125.58797792, -36.57466125))\n",
    "    ]\n",
    "\n",
    "    # Separate the known pixel coordinates (x, y) and ground coordinates (X, Y)\n",
    "    pixel_coords, ground_coords = zip(*known_coordinates)\n",
    "\n",
    "    # Fit a linear regression model\n",
    "    layer2_model = LinearRegression()\n",
    "    layer2_model.fit(pixel_coords, np.array(ground_coords))\n",
    "\n",
    "    # Assuming you have a list of 60 pairs of known coordinates, where each pair is a tuple (pixel, ground)\n",
    "    known_coordinates = [\n",
    "        ((6, 45), (196.92764426, -125.22348913, -21.73018837)),\n",
    "        ((3, 146), (236.56908063, -127.23658533,  -22.03581619)),\n",
    "        ((3, 237), (273.5059388,  -126.81603355,  -21.57911491)),\n",
    "        ((5, 328), (312.32962499, -128.64442561,  -19.99492645)),\n",
    "        ((11, 426), (352.61157869, -126.01972705,  -19.44989204)),\n",
    "\n",
    "        ((117, 432), (355.14293162, -82.67091872, -19.86775208)),\n",
    "        ((116, 338 ), (317.97714394, -82.06928871, -20.2526989)),\n",
    "        ((120, 249), (281.37323849, -80.34140055, -21.46855927)),\n",
    "        ((125, 155), (242.2471473,  -77.70260673, -22.59416771)),\n",
    "        ((134, 49), (200.26496155, -71.52061314, -23.70256042)),\n",
    "\n",
    "        ((227, 35), (195.87959428, -34.98213259, -23.97964096)),\n",
    "        ((227, 135), (237.64442275, -34.91865281, -22.92924309)),\n",
    "        ((233, 225), (274.7174276,  -33.24489408, -21.94892502)),\n",
    "        ((250, 330), (315.41460061, -28.62126874, -21.05791664)),\n",
    "        ((255, 433), (356.86948046, -26.22146481, -19.83654594)),\n",
    "\n",
    "        ((359, 433), (358.32351343,  14.41260995, -20.09869194)),\n",
    "        ((365, 355), (326.27588664,  16.5593473, -20.91016197)),\n",
    "        ((366, 259), (288.57803555,  20.57449715, -21.62224197)),\n",
    "        ((379, 162), (248.98329236,  23.83523211, -22.04266548)),\n",
    "        ((379,54), (205.77546796,  26.14977197, -23.88983345)),\n",
    "\n",
    "        ((454, 49), (203.87454408,  55.22593241, -23.7526474)),\n",
    "        ((453, 151), (246.29422608,  54.05664616, -22.77240753)),\n",
    "        ((452, 238), (281.0962986,   52.50358319, -21.95423889)),\n",
    "        ((442, 340), (320.04448135,  47.212418,   -21.01519012)),\n",
    "        ((436, 436), (360.80058399,  46.22674863, -20.06522942)),\n",
    "\n",
    "        ((515, 440), (363.09674139,  76.66862068, -19.78180313)),\n",
    "        ((512, 354), (326.75653736,  76.900997,   -20.66069031)),\n",
    "        ((505, 254), (288.07669075,  74.95782651, -21.65236664)),\n",
    "        ((509, 149), (245.71055144,  76.94604428, -22.2881813)),\n",
    "        ((502, 37), (198.75460512,  76.30178114, -23.60990715)),\n",
    "\n",
    "        ((599, 35), (200.20696986, 115.24439714, -23.51133347)),\n",
    "        ((599, 136), (240.88112097, 115.92197151, -22.57105446)),\n",
    "        ((608,233), (280.78544952, 117.65400972, -21.85529327)),\n",
    "        ((622, 345), (323.50137186, 122.58934153, -20.66569519)),\n",
    "        ((623, 436), (364.92678188, 122.82714746, -20.01245689))\n",
    "    ]\n",
    "\n",
    "    # Separate the known pixel coordinates (x, y) and ground coordinates (X, Y)\n",
    "    pixel_coords, ground_coords = zip(*known_coordinates)\n",
    "\n",
    "    # Fit a linear regression model\n",
    "    layer3_model = LinearRegression()\n",
    "    layer3_model.fit(pixel_coords, np.array(ground_coords))\n",
    "    \n",
    "    return (layer1_model, layer2_model, layer3_model)\n",
    "\n",
    "# Now you can convert any pixel coordinates (x, y) to ground coordinates (X, Y)\n",
    "def convert_pixel_to_ground(layer, x, y):\n",
    "    pixel = np.array([[x, y]])\n",
    "    if (layer==1):\n",
    "        ground = layer1_model.predict(pixel)\n",
    "        return tuple(ground[0])\n",
    "    elif (layer==2):\n",
    "        ground = layer2_model.predict(pixel)\n",
    "        return tuple(ground[0])\n",
    "    elif (layer==3):\n",
    "        ground = layer3_model.predict(pixel)\n",
    "        return tuple(ground[0])\n",
    "\n",
    "layer1_model, layer2_model, layer3_model = return_models()\n",
    "\n",
    "# Example usage:\n",
    "layer = 3\n",
    "x_pixel = 6\n",
    "y_pixel = 45\n",
    "X_ground, Y_ground, Z_ground = convert_pixel_to_ground(layer, x_pixel, y_pixel)\n",
    "\n",
    "print(\"Pixel Coordinates:\", (x_pixel, y_pixel))\n",
    "print(\"Ground Coordinates:\", (X_ground, Y_ground, Z_ground))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--weights WEIGHTS [WEIGHTS ...]]\n",
      "                             [--source SOURCE] [--data DATA]\n",
      "                             [--imgsz IMGSZ [IMGSZ ...]]\n",
      "                             [--conf-thres CONF_THRES] [--iou-thres IOU_THRES]\n",
      "                             [--max-det MAX_DET] [--device DEVICE]\n",
      "                             [--view-img] [--save-txt] [--save-conf]\n",
      "                             [--save-crop] [--nosave]\n",
      "                             [--classes CLASSES [CLASSES ...]]\n",
      "                             [--agnostic-nms] [--augment] [--visualize]\n",
      "                             [--update] [--project PROJECT] [--name NAME]\n",
      "                             [--exist-ok] [--line-thickness LINE_THICKNESS]\n",
      "                             [--hide-labels] [--hide-conf] [--half] [--dnn]\n",
      "                             [--vid-stride VID_STRIDE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9023 --control=9021 --hb=9020 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"f7a85e19-3d04-414a-a234-190b9a958927\" --shell=9022 --transport=\"tcp\" --iopub=9024 --f=/home/jin/.local/share/jupyter/runtime/kernel-v2-35374kbM4FN22hh48.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = f\"python detect.py --weights runs/train/yolov7-custom/weights/best.pt --conf 0.8 --img-size 640 --source 0 --no-trace --save-txt\"\n",
    "result = subprocess.run(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First of all, we have to connect with dobot\n",
    "\n",
    "import threading\n",
    "from dobot_api import DobotApiDashboard, DobotApi, DobotApiMove, MyType\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "\n",
    "# 전역 변수 (현재 좌표)\n",
    "current_actual = None\n",
    "\n",
    "def connect_robot(ip):\n",
    "    try:\n",
    "        dashboard_p = 29999\n",
    "        move_p = 30003\n",
    "        feed_p = 30004\n",
    "        print(\"연결 설정 중...\")\n",
    "\n",
    "        dashboard = DobotApiDashboard(ip, dashboard_p)\n",
    "        move = DobotApiMove(ip, move_p)\n",
    "        feed = DobotApi(ip, feed_p)\n",
    "        print(\"연결 성공!!\")\n",
    "\n",
    "        return dashboard, move, feed\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"연결 실패\")\n",
    "        raise e\n",
    "    \n",
    "\n",
    "def robot_clear(dashboard : DobotApiDashboard):\n",
    "    dashboard.ClearError()\n",
    "\n",
    "def robot_speed(dashboard : DobotApiDashboard, speed_value):\n",
    "    dashboard.SpeedFactor(speed_value)\n",
    "\n",
    "def gripper_DO(dashboard : DobotApiDashboard, index, status):\n",
    "    dashboard.ToolDO(index, status)\n",
    "\n",
    "def get_Pose(dashboard : DobotApiDashboard):\n",
    "    dashboard.GetPose()\n",
    "\n",
    "def run_point(move: DobotApiMove, point_list: list):\n",
    "    move.MovL(point_list[0], point_list[1], point_list[2], point_list[3])\n",
    "\n",
    "def get_feed(feed: DobotApi):\n",
    "    global current_actual\n",
    "    hasRead = 0\n",
    "\n",
    "    while True:\n",
    "        data = bytes()\n",
    "        while hasRead < 1440:\n",
    "            temp = feed.socket_dobot.recv(1440 - hasRead)\n",
    "            if len(temp) > 0:\n",
    "                hasRead += len(temp)\n",
    "                data += temp\n",
    "        hasRead = 0\n",
    "        a = np.frombuffer(data, dtype=MyType)\n",
    "\n",
    "        if hex((a['test_value'][0])) == '0x123456789abcdef':\n",
    "            current_actual = a[\"tool_vector_actual\"][0]     # Refresh Properties\n",
    "        sleep(0.001)\n",
    "\n",
    "def wait_arrive(point_list):\n",
    "    global current_actual\n",
    "    while True:\n",
    "        is_arrive = True\n",
    "        if current_actual is not None:\n",
    "            for index in range(4):\n",
    "                if (abs(current_actual[index] - point_list[index]) > 1):\n",
    "                    is_arrive = False\n",
    "            if is_arrive:\n",
    "                return\n",
    "        sleep(0.001)\n",
    "\n",
    "# 입력 파라미터\n",
    "ip = \"192.168.1.6\"              # Robot의 IP 주소\n",
    "gripper_port = 1                # 그리퍼 포트 번호\n",
    "speed_value = 100                # 로봇 속도 (1~100 사이의 값 입력)\n",
    "\n",
    "## 로봇의 원위치 좌표 (x, y, z, yaw) unit : mm, degree\n",
    "point_home = [175.67116488, -128.80691014, 32.12535477, 86.67063904]\n",
    "\n",
    "# 로봇 연결\n",
    "dashboard, move, feed = connect_robot(ip)\n",
    "dashboard.EnableRobot()\n",
    "print(\"이제 로봇을 사용할 수 있습니다!\")\n",
    "\n",
    "# 쓰레드 설정\n",
    "feed_thread = threading.Thread(target=get_feed, args=(feed,))\n",
    "feed_thread.setDaemon(True)\n",
    "feed_thread.start()\n",
    "\n",
    "# 로봇 상태 초기화 1 : 로봇 에러 메시지 초기화\n",
    "robot_clear(dashboard) \n",
    "\n",
    "# 로봇 상태 초기화 2 : 로봇 속도 조절\n",
    "robot_speed(dashboard, speed_value)\n",
    "\n",
    "## 로봇 원위치하기!\n",
    "run_point(move, point_home)\n",
    "wait_arrive(point_home)\n",
    "#sleep(3)\n",
    "\n",
    "## 1단계: 3층 센터 인식 후, 해당색깔로 이동\n",
    "\n",
    "## 1단계-1: 색깔 순서를 리스트에 저장하기\n",
    "## (color_box[2]에서 2는 뭘 의미하는건가요?) (몇 초 이상 유지되어야지만 저장되게할까요?) (저장된 이름이 red, green, yellow가 맞는지 확인)\n",
    "# char color_list = [0,0,0]\n",
    "\n",
    "# if ((color_box[2] == \"red_center\") && (color_box[1] == \"red\")):\n",
    "#     color_list[0] = 'R'\n",
    "# elif ((color_box[2] == \"green_center\") && (color_box[1] == \"green\")):\n",
    "#     color_list[0] = 'G'\n",
    "# elif ((color_box[2] == \"yellow_center\") && (color_box[1] == \"yellow\")):\n",
    "#     color_list[0] = 'Y'\n",
    "# else:\n",
    "#     print(\"ERROR!\")\n",
    "#         return\n",
    "# 로봇 끄기\n",
    "dashboard.DisableRobot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
